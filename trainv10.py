# =============================================================================
# PROGRAMME D'ENTRAÃŽNEMENT POUR RECONNAISSANCE VOCALE DU CODE MORSE
# =============================================================================
# Ce programme entraÃ®ne un modÃ¨le d'intelligence artificielle Ã  reconnaÃ®tre 
# le code Morse parlÃ© et le convertir en texte
# =============================================================================

# IMPORTATION DES BIBLIOTHÃˆQUES NÃ‰CESSAIRES
# ------------------------------------------
import os           # Pour naviguer dans les dossiers
import json         # Pour lire les fichiers de configuration
import numpy as np  # Pour les calculs mathÃ©matiques sur les tableaux
import tensorflow as tf  # BibliothÃ¨que d'IA de Google
from tensorflow import keras
from sklearn.model_selection import train_test_split  # Pour diviser les donnÃ©es
from tensorflow.keras.layers import Input, Conv1D, Bidirectional, LSTM, Dense, Dropout, BatchNormalization
from tensorflow.keras.models import Model
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint

# CONFIGURATION DU PROGRAMME
# ---------------------------
# Ces valeurs contrÃ´lent comment le modÃ¨le sera entraÃ®nÃ©
PREPROCESSED_DIR = "preprocessed_data"  # Dossier contenant les donnÃ©es audio prÃ©parÃ©es
MAX_SEQ_LENGTH = 2000   # Longueur maximale d'un Ã©chantillon audio (en frames)
BATCH_SIZE = 32         # Nombre d'Ã©chantillons traitÃ©s en mÃªme temps
EPOCHS = 100            # Nombre de fois oÃ¹ on passe sur toutes les donnÃ©es
MODEL_SAVE_PATH = "morse_model.keras"  # Nom du fichier oÃ¹ sauvegarder le modÃ¨le

def load_data():
    """
    FONCTION DE CHARGEMENT DES DONNÃ‰ES
    ==================================
    Cette fonction lit tous les fichiers audio et leurs transcriptions,
    puis les prÃ©pare pour l'entraÃ®nement du modÃ¨le.
    
    Retourne:
    - X: Les donnÃ©es audio (spectrogrammes MFCC)
    - y: Les textes correspondants (labels)
    - input_lengths: Longueur de chaque audio
    - label_lengths: Longueur de chaque texte
    - char_to_int: Dictionnaire pour convertir lettres en chiffres
    """
    
    # CHARGEMENT DU FICHIER DE MÃ‰TADONNÃ‰ES
    # -------------------------------------
    # Le fichier metadata.json contient la liste de tous les Ã©chantillons
    # et le dictionnaire de conversion caractÃ¨re -> chiffre
    with open(os.path.join(PREPROCESSED_DIR, "metadata.json"), 'r') as f:
        metadata = json.load(f)
    
    # PRÃ‰PARATION DU DICTIONNAIRE DE CARACTÃˆRES
    # ------------------------------------------
    # Le modÃ¨le ne comprend que les chiffres, on doit convertir les lettres
    char_to_int = metadata["char_map"]
    char_to_int['<PAD>'] = 0  # Token de remplissage pour Ã©galiser les longueurs
    char_to_int['<BLANK>'] = len(char_to_int)  # Token vide pour l'algorithme CTC

    # INITIALISATION DES LISTES DE DONNÃ‰ES
    # -------------------------------------
    X = []              # Contiendra les donnÃ©es audio
    y = []              # Contiendra les textes
    input_lengths = []  # Longueur de chaque audio
    label_lengths = []  # Longueur de chaque texte

    # CHARGEMENT DE CHAQUE Ã‰CHANTILLON
    # ---------------------------------
    for item in metadata["files"]:
        try:
            # Charger le fichier audio prÃ©processÃ© (MFCC)
            mfcc = np.load(os.path.join(PREPROCESSED_DIR, "mfccs", item["mfcc_file"]))
            text_label = item["text_label"]
            
            # VALIDATION DE LA QUALITÃ‰ DES DONNÃ‰ES
            # ------------------------------------
            # On s'assure que l'Ã©chantillon est utilisable
            seq_length = min(mfcc.shape[0], MAX_SEQ_LENGTH)
            if seq_length == 0 or len(text_label) == 0:
                continue  # Ignorer les Ã©chantillons vides
                
            # VÃ‰RIFICATION POUR L'ALGORITHME CTC
            # -----------------------------------
            # L'audio doit Ãªtre plus long que le texte pour que CTC fonctionne
            if seq_length <= len(text_label):
                continue
                
            # AJOUT DES DONNÃ‰ES VALIDES
            # -------------------------
            X.append(mfcc[:seq_length])  # Tronquer si trop long
            y.append([char_to_int[c] for c in text_label])  # Convertir lettres en chiffres
            input_lengths.append(seq_length)
            label_lengths.append(len(text_label))
            
        except Exception as e:
            print(f"Erreur lors du chargement de {item['mfcc_file']}: {str(e)}")
            continue

    # VÃ‰RIFICATION QU'ON A DES DONNÃ‰ES
    # --------------------------------
    if len(X) == 0:
        raise ValueError("Aucun Ã©chantillon valide trouvÃ©!")

    # Ã‰GALISATION DE LA TAILLE DES DONNÃ‰ES (PADDING)
    # -----------------------------------------------
    # Tous les Ã©chantillons doivent avoir la mÃªme taille pour l'entraÃ®nement
    max_label_length = max(label_lengths)
    X_padded = np.zeros((len(X), MAX_SEQ_LENGTH, 39), dtype=np.float32)  # 39 = nb de features MFCC
    y_padded = np.zeros((len(y), max_label_length), dtype=np.int32)
    
    # Remplir les tableaux avec nos donnÃ©es
    for i, (mfcc, label) in enumerate(zip(X, y)):
        X_padded[i, :len(mfcc)] = mfcc      # Copier l'audio
        y_padded[i, :len(label)] = label    # Copier le texte

    return X_padded, y_padded, np.array(input_lengths), np.array(label_lengths), char_to_int

def build_model(input_shape, num_classes):
    """
    CONSTRUCTION DE L'ARCHITECTURE DU MODÃˆLE
    ========================================
    Cette fonction crÃ©e le "cerveau" de notre IA qui apprendra Ã  reconnaÃ®tre
    le code Morse. Le modÃ¨le utilise l'algorithme CTC (Connectionist Temporal
    Classification) qui est spÃ©cialement conÃ§u pour aligner audio et texte.
    
    Le modÃ¨le a plusieurs couches:
    1. Couches convolutionnelles : extraient les caractÃ©ristiques de l'audio
    2. Couches LSTM bidirectionnelles : analysent les sÃ©quences dans les deux sens
    3. Couche de sortie : produit les probabilitÃ©s pour chaque caractÃ¨re
    """
    
    # DÃ‰FINITION DES ENTRÃ‰ES DU MODÃˆLE
    # ---------------------------------
    input_mfcc = Input(shape=input_shape, name='input_mfcc')        # Audio d'entrÃ©e
    input_length = Input(shape=(1,), name='input_length', dtype='int32')  # Longueur audio
    label_length = Input(shape=(1,), name='label_length', dtype='int32')  # Longueur texte
    labels = Input(shape=(None,), name='labels', dtype='int32')     # Texte cible
    
    # COUCHES D'EXTRACTION DE CARACTÃ‰RISTIQUES
    # -----------------------------------------
    # Ces couches analysent l'audio pour dÃ©tecter les motifs du Morse
    
    # PremiÃ¨re couche convolutionnelle
    x = Conv1D(128, 3, padding='same', activation='relu')(input_mfcc)
    x = BatchNormalization()(x)  # Normalise les donnÃ©es pour stabiliser l'entraÃ®nement
    x = Dropout(0.3)(x)         # Ã‰vite le sur-apprentissage en "oubliant" 30% des connexions
    
    # DeuxiÃ¨me couche convolutionnelle
    x = Conv1D(128, 3, padding='same', activation='relu')(x)
    x = BatchNormalization()(x)
    x = Dropout(0.3)(x)
    
    # COUCHES DE TRAITEMENT SÃ‰QUENTIEL
    # ---------------------------------
    # Ces couches analysent l'audio dans le temps (passÃ© et futur)
    
    # PremiÃ¨re couche LSTM bidirectionnelle (128 neurones dans chaque direction)
    x = Bidirectional(LSTM(128, return_sequences=True))(x)
    x = Dropout(0.3)(x)
    
    # DeuxiÃ¨me couche LSTM bidirectionnelle (64 neurones dans chaque direction)
    x = Bidirectional(LSTM(64, return_sequences=True))(x)
    x = Dropout(0.3)(x)
    
    # COUCHE DE SORTIE
    # ----------------
    # Produit les probabilitÃ©s pour chaque caractÃ¨re (+1 pour le token "blank")
    predictions = Dense(num_classes + 1, activation='softmax', name='predictions')(x)
    
    # COUCHE DE PERTE CTC
    # -------------------
    # Calcule l'erreur entre les prÃ©dictions et la vraie transcription
    ctc_loss = keras.layers.Lambda(
        lambda args: keras.backend.ctc_batch_cost(args[0], args[1], args[2], args[3]),
        output_shape=(1,),
        name='ctc_loss'
    )([labels, predictions, input_length, label_length])
    
    # CRÃ‰ATION DES MODÃˆLES
    # --------------------
    # ModÃ¨le d'entraÃ®nement (avec calcul de perte)
    training_model = Model(
        inputs=[input_mfcc, labels, input_length, label_length],
        outputs=ctc_loss
    )
    
    # ModÃ¨le de prÃ©diction (pour utilisation aprÃ¨s entraÃ®nement)
    prediction_model = Model(inputs=input_mfcc, outputs=predictions)
    
    return training_model, prediction_model

class DataGenerator(keras.utils.Sequence):
    """
    GÃ‰NÃ‰RATEUR DE DONNÃ‰ES PERSONNALISÃ‰
    ==================================
    Cette classe organise les donnÃ©es en "lots" (batches) pour l'entraÃ®nement.
    Elle permet de traiter de gros volumes de donnÃ©es sans saturer la mÃ©moire.
    
    Avantages:
    - MÃ©lange les donnÃ©es Ã  chaque Ã©poque
    - Traite les donnÃ©es par petits groupes
    - PrÃ©pare automatiquement le format requis par CTC
    """
    
    def __init__(self, X, y, input_lengths, label_lengths, batch_size=32, shuffle=True):
        """
        INITIALISATION DU GÃ‰NÃ‰RATEUR
        ----------------------------
        """
        self.X = X                          # DonnÃ©es audio
        self.y = y                          # Textes correspondants
        self.input_lengths = input_lengths   # Longueurs des audios
        self.label_lengths = label_lengths   # Longueurs des textes
        self.batch_size = batch_size        # Taille des lots
        self.shuffle = shuffle              # MÃ©langer ou pas
        self.indices = np.arange(len(self.X))  # Index des Ã©chantillons
        self.on_epoch_end()                 # MÃ©lange initial
    
    def __len__(self):
        """Retourne le nombre de lots par Ã©poque"""
        return int(np.ceil(len(self.X) / self.batch_size))
    
    def __getitem__(self, index):
        """
        GÃ‰NÃ‰RATION D'UN LOT DE DONNÃ‰ES
        ------------------------------
        Cette mÃ©thode est appelÃ©e pour chaque lot pendant l'entraÃ®nement
        """
        # SÃ©lectionner les indices pour ce lot
        batch_indices = self.indices[index * self.batch_size:(index + 1) * self.batch_size]
        
        # RÃ©cupÃ©rer les donnÃ©es correspondantes
        batch_X = self.X[batch_indices]
        batch_y = self.y[batch_indices]
        batch_input_lengths = self.input_lengths[batch_indices]
        batch_label_lengths = self.label_lengths[batch_indices]
        
        # PRÃ‰PARATION POUR LE MODÃˆLE CTC
        # -------------------------------
        # Le modÃ¨le CTC a besoin d'un format spÃ©cial
        inputs = {
            'input_mfcc': batch_X,
            'labels': batch_y,
            'input_length': batch_input_lengths.reshape(-1, 1),
            'label_length': batch_label_lengths.reshape(-1, 1)
        }
        
        # CTC calcule sa propre perte, on donne des cibles factices
        targets = np.zeros((len(batch_indices), 1))
        
        return inputs, targets
    
    def on_epoch_end(self):
        """MÃ©lange les donnÃ©es Ã  la fin de chaque Ã©poque"""
        if self.shuffle:
            np.random.shuffle(self.indices)

# =============================================================================
# PROGRAMME PRINCIPAL D'ENTRAÃŽNEMENT
# =============================================================================

if __name__ == "__main__":
    
    # Ã‰TAPE 1 : CHARGEMENT ET VALIDATION DES DONNÃ‰ES
    # ===============================================
    print("ðŸ“¥ Chargement des donnÃ©es...")
    X, y, input_lengths, label_lengths, char_to_int = load_data()
    
    # Affichage des statistiques
    print(f"âœ… {len(X)} Ã©chantillons valides chargÃ©s")
    print(f"ðŸ“š Vocabulaire: {len(char_to_int)} caractÃ¨res")
    print(f"ðŸŽµ Longueur audio: {input_lengths.min()} - {input_lengths.max()} frames")
    print(f"ðŸ“ Longueur texte: {label_lengths.min()} - {label_lengths.max()} caractÃ¨res")
    
    # Ã‰TAPE 2 : DIVISION ENTRAÃŽNEMENT/VALIDATION
    # ===========================================
    # On garde 80% des donnÃ©es pour l'entraÃ®nement, 20% pour tester
    print("\nðŸ”€ Division des donnÃ©es...")
    indices = np.arange(len(X))
    train_idx, val_idx = train_test_split(indices, test_size=0.2, random_state=42)
    
    # SÃ©paration des donnÃ©es
    X_train, X_val = X[train_idx], X[val_idx]
    y_train, y_val = y[train_idx], y[val_idx]
    input_lengths_train, input_lengths_val = input_lengths[train_idx], input_lengths[val_idx]
    label_lengths_train, label_lengths_val = label_lengths[train_idx], label_lengths[val_idx]
    
    # Ã‰TAPE 3 : CRÃ‰ATION DES GÃ‰NÃ‰RATEURS DE DONNÃ‰ES
    # ==============================================
    print("ðŸ­ CrÃ©ation des gÃ©nÃ©rateurs de donnÃ©es...")
    
    # GÃ©nÃ©rateur pour l'entraÃ®nement (mÃ©lange activÃ©)
    train_generator = DataGenerator(
        X_train, y_train, input_lengths_train, label_lengths_train,
        batch_size=BATCH_SIZE, shuffle=True
    )
    
    # GÃ©nÃ©rateur pour la validation (pas de mÃ©lange)
    val_generator = DataGenerator(
        X_val, y_val, input_lengths_val, label_lengths_val,
        batch_size=BATCH_SIZE, shuffle=False
    )
    
    # Ã‰TAPE 4 : CONSTRUCTION DU MODÃˆLE
    # =================================
    print("ðŸ—ï¸ Construction du modÃ¨le d'IA...")
    training_model, prediction_model = build_model((MAX_SEQ_LENGTH, 39), len(char_to_int))
    
    # Ã‰TAPE 5 : COMPILATION DU MODÃˆLE D'ENTRAÃŽNEMENT
    # ===============================================
    # Configuration de l'optimiseur et de la fonction de perte
    training_model.compile(
        optimizer=keras.optimizers.Adam(learning_rate=0.001),  # Algorithme d'optimisation
        loss={'ctc_loss': lambda y_true, y_pred: y_pred}       # Perte CTC dÃ©jÃ  calculÃ©e
    )
    
    # Affichage des informations du modÃ¨le
    print(f"\nðŸ—‚ï¸ Architecture du modÃ¨le:")
    print(f"ðŸ“Š Ã‰chantillons d'entraÃ®nement: {len(X_train)}")
    print(f"ðŸ§ª Ã‰chantillons de validation: {len(X_val)}")
    print(f"ðŸ”¤ Taille du vocabulaire: {len(char_to_int)} caractÃ¨res")
    training_model.summary()  # Affiche la structure dÃ©taillÃ©e
    
    # Ã‰TAPE 6 : CONFIGURATION DES CALLBACKS
    # ======================================
    # Les callbacks sont des fonctions appelÃ©es pendant l'entraÃ®nement
    callbacks = [
        # ArrÃªt prÃ©coce si le modÃ¨le ne s'amÃ©liore plus
        EarlyStopping(
            monitor='val_loss',           # Surveiller la perte de validation
            patience=10,                  # Attendre 10 Ã©poques sans amÃ©lioration
            restore_best_weights=True     # Restaurer les meilleurs poids
        ),
        
        # Sauvegarde automatique du meilleur modÃ¨le
        ModelCheckpoint(
            MODEL_SAVE_PATH.replace('.keras', '_best.keras'),  # Nom du fichier
            monitor='val_loss',           # CritÃ¨re de sÃ©lection
            save_best_only=True,         # Sauvegarder seulement le meilleur
            mode='min',                  # Minimiser la perte
            save_weights_only=False      # Sauvegarder le modÃ¨le complet
        )
    ]
    
    # Ã‰TAPE 7 : LANCEMENT DE L'ENTRAÃŽNEMENT
    # ======================================
    print("ðŸš€ DÃ©but de l'entraÃ®nement...")
    print("   (Cela peut prendre plusieurs heures selon votre matÃ©riel)")
    
    # EntraÃ®nement proprement dit
    history = training_model.fit(
        train_generator,              # DonnÃ©es d'entraÃ®nement
        validation_data=val_generator, # DonnÃ©es de validation
        epochs=EPOCHS,               # Nombre d'Ã©poques maximum
        callbacks=callbacks,         # Fonctions de callback
        verbose=1                    # Affichage dÃ©taillÃ©
    )
    
    # Ã‰TAPE 8 : SAUVEGARDE FINALE
    # ============================
    print("\nðŸ’¾ Sauvegarde du modÃ¨le...")
    
    # Sauvegarder le modÃ¨le de prÃ©diction
    prediction_model.save(MODEL_SAVE_PATH)
    print(f"âœ… ModÃ¨le de prÃ©diction sauvegardÃ©: {MODEL_SAVE_PATH}")
    
    # Sauvegarder l'historique d'entraÃ®nement pour analyse
    with open('training_history.json', 'w') as f:
        json.dump(history.history, f, indent=2)
    print("ðŸ“Š Historique d'entraÃ®nement sauvegardÃ©: training_history.json")
    
    print("\nðŸŽ‰ EntraÃ®nement terminÃ© avec succÃ¨s!")
    print("   Votre modÃ¨le est prÃªt Ã  reconnaÃ®tre le code Morse!")

# =============================================================================
# RÃ‰SUMÃ‰ DU FONCTIONNEMENT
# =============================================================================
"""
Ce programme fonctionne en plusieurs Ã©tapes:

1. PRÃ‰PARATION DES DONNÃ‰ES
   - Charge les fichiers audio prÃ©processÃ©s (MFCC)
   - Charge les transcriptions textuelles correspondantes
   - Convertit les lettres en nombres pour le modÃ¨le
   - Ã‰galise la taille de tous les Ã©chantillons

2. ARCHITECTURE DU MODÃˆLE
   - Couches convolutionnelles: dÃ©tectent les motifs dans l'audio
   - Couches LSTM: analysent les sÃ©quences temporelles
   - Algorithme CTC: aligne automatiquement audio et texte

3. ENTRAÃŽNEMENT
   - Le modÃ¨le apprend Ã  associer les sons Morse aux lettres
   - Utilise les donnÃ©es de validation pour Ã©viter le sur-apprentissage
   - Sauvegarde automatiquement le meilleur modÃ¨le

4. RÃ‰SULTAT
   - Un modÃ¨le capable de transcrire du code Morse parlÃ© en texte
   - Fichiers de sauvegarde pour utilisation ultÃ©rieure
"""